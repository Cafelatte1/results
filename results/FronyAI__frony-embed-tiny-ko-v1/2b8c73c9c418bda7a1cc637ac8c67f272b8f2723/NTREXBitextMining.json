{
  "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
  "task_name": "NTREXBitextMining",
  "mteb_version": "1.36.38",
  "scores": {
    "test": [
      {
        "precision": 0.529083,
        "recall": 0.617426,
        "f1": 0.552938,
        "accuracy": 0.617426,
        "main_score": 0.552938,
        "hf_subset": "arb_Arab-kor_Hang",
        "languages": [
          "arb-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.492994,
        "recall": 0.592389,
        "f1": 0.519858,
        "accuracy": 0.592389,
        "main_score": 0.519858,
        "hf_subset": "ben_Beng-kor_Hang",
        "languages": [
          "ben-Beng",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.629653,
        "recall": 0.705058,
        "f1": 0.649585,
        "accuracy": 0.705058,
        "main_score": 0.649585,
        "hf_subset": "deu_Latn-kor_Hang",
        "languages": [
          "deu-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.592046,
        "recall": 0.68002,
        "f1": 0.615826,
        "accuracy": 0.68002,
        "main_score": 0.615826,
        "hf_subset": "ell_Grek-kor_Hang",
        "languages": [
          "ell-Grek",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.741808,
        "recall": 0.808713,
        "f1": 0.761107,
        "accuracy": 0.808713,
        "main_score": 0.761107,
        "hf_subset": "eng_Latn-kor_Hang",
        "languages": [
          "eng-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.639349,
        "recall": 0.723085,
        "f1": 0.663151,
        "accuracy": 0.723085,
        "main_score": 0.663151,
        "hf_subset": "fas_Arab-kor_Hang",
        "languages": [
          "fas-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.523074,
        "recall": 0.610916,
        "f1": 0.546641,
        "accuracy": 0.610916,
        "main_score": 0.546641,
        "hf_subset": "fin_Latn-kor_Hang",
        "languages": [
          "fin-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.581819,
        "recall": 0.668503,
        "f1": 0.60533,
        "accuracy": 0.668503,
        "main_score": 0.60533,
        "hf_subset": "fra_Latn-kor_Hang",
        "languages": [
          "fra-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.526887,
        "recall": 0.614422,
        "f1": 0.550136,
        "accuracy": 0.614422,
        "main_score": 0.550136,
        "hf_subset": "heb_Hebr-kor_Hang",
        "languages": [
          "heb-Hebr",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.565094,
        "recall": 0.657486,
        "f1": 0.591036,
        "accuracy": 0.657486,
        "main_score": 0.591036,
        "hf_subset": "hin_Deva-kor_Hang",
        "languages": [
          "hin-Deva",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.543276,
        "recall": 0.635954,
        "f1": 0.568244,
        "accuracy": 0.635954,
        "main_score": 0.568244,
        "hf_subset": "hun_Latn-kor_Hang",
        "languages": [
          "hun-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.664852,
        "recall": 0.745618,
        "f1": 0.688284,
        "accuracy": 0.745618,
        "main_score": 0.688284,
        "hf_subset": "ind_Latn-kor_Hang",
        "languages": [
          "ind-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.711397,
        "recall": 0.784176,
        "f1": 0.733254,
        "accuracy": 0.784176,
        "main_score": 0.733254,
        "hf_subset": "jpn_Jpan-kor_Hang",
        "languages": [
          "jpn-Jpan",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.37921,
        "recall": 0.473711,
        "f1": 0.401909,
        "accuracy": 0.473711,
        "main_score": 0.401909,
        "hf_subset": "kor_Hang-arb_Arab",
        "languages": [
          "kor-Hang",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.452813,
        "recall": 0.556335,
        "f1": 0.47994,
        "accuracy": 0.556335,
        "main_score": 0.47994,
        "hf_subset": "kor_Hang-ben_Beng",
        "languages": [
          "kor-Hang",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.491223,
        "recall": 0.577366,
        "f1": 0.512075,
        "accuracy": 0.577366,
        "main_score": 0.512075,
        "hf_subset": "kor_Hang-deu_Latn",
        "languages": [
          "kor-Hang",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.462365,
        "recall": 0.560841,
        "f1": 0.486938,
        "accuracy": 0.560841,
        "main_score": 0.486938,
        "hf_subset": "kor_Hang-ell_Grek",
        "languages": [
          "kor-Hang",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.674652,
        "recall": 0.743615,
        "f1": 0.693031,
        "accuracy": 0.743615,
        "main_score": 0.693031,
        "hf_subset": "kor_Hang-eng_Latn",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.542885,
        "recall": 0.628943,
        "f1": 0.56554,
        "accuracy": 0.628943,
        "main_score": 0.56554,
        "hf_subset": "kor_Hang-fas_Arab",
        "languages": [
          "kor-Hang",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.364779,
        "recall": 0.449675,
        "f1": 0.384599,
        "accuracy": 0.449675,
        "main_score": 0.384599,
        "hf_subset": "kor_Hang-fin_Latn",
        "languages": [
          "kor-Hang",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.477646,
        "recall": 0.55333,
        "f1": 0.495967,
        "accuracy": 0.55333,
        "main_score": 0.495967,
        "hf_subset": "kor_Hang-fra_Latn",
        "languages": [
          "kor-Hang",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.42079,
        "recall": 0.516775,
        "f1": 0.444682,
        "accuracy": 0.516775,
        "main_score": 0.444682,
        "hf_subset": "kor_Hang-heb_Hebr",
        "languages": [
          "kor-Hang",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.536454,
        "recall": 0.632949,
        "f1": 0.562592,
        "accuracy": 0.632949,
        "main_score": 0.562592,
        "hf_subset": "kor_Hang-hin_Deva",
        "languages": [
          "kor-Hang",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.40919,
        "recall": 0.503756,
        "f1": 0.432602,
        "accuracy": 0.503756,
        "main_score": 0.432602,
        "hf_subset": "kor_Hang-hun_Latn",
        "languages": [
          "kor-Hang",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.544939,
        "recall": 0.623435,
        "f1": 0.564532,
        "accuracy": 0.623435,
        "main_score": 0.564532,
        "hf_subset": "kor_Hang-ind_Latn",
        "languages": [
          "kor-Hang",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.691853,
        "recall": 0.764146,
        "f1": 0.713004,
        "accuracy": 0.764146,
        "main_score": 0.713004,
        "hf_subset": "kor_Hang-jpn_Jpan",
        "languages": [
          "kor-Hang",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.400398,
        "recall": 0.49324,
        "f1": 0.422554,
        "accuracy": 0.49324,
        "main_score": 0.422554,
        "hf_subset": "kor_Hang-lit_Latn",
        "languages": [
          "kor-Hang",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.537199,
        "recall": 0.624437,
        "f1": 0.559497,
        "accuracy": 0.624437,
        "main_score": 0.559497,
        "hf_subset": "kor_Hang-nld_Latn",
        "languages": [
          "kor-Hang",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.394048,
        "recall": 0.475213,
        "f1": 0.412816,
        "accuracy": 0.475213,
        "main_score": 0.412816,
        "hf_subset": "kor_Hang-pol_Latn",
        "languages": [
          "kor-Hang",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.492794,
        "recall": 0.57987,
        "f1": 0.514496,
        "accuracy": 0.57987,
        "main_score": 0.514496,
        "hf_subset": "kor_Hang-por_Latn",
        "languages": [
          "kor-Hang",
          "por-Latn"
        ]
      },
      {
        "precision": 0.50048,
        "recall": 0.590886,
        "f1": 0.523252,
        "accuracy": 0.590886,
        "main_score": 0.523252,
        "hf_subset": "kor_Hang-rus_Cyrl",
        "languages": [
          "kor-Hang",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.494641,
        "recall": 0.573861,
        "f1": 0.514033,
        "accuracy": 0.573861,
        "main_score": 0.514033,
        "hf_subset": "kor_Hang-spa_Latn",
        "languages": [
          "kor-Hang",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.319065,
        "recall": 0.400601,
        "f1": 0.337529,
        "accuracy": 0.400601,
        "main_score": 0.337529,
        "hf_subset": "kor_Hang-swa_Latn",
        "languages": [
          "kor-Hang",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.520924,
        "recall": 0.605909,
        "f1": 0.541477,
        "accuracy": 0.605909,
        "main_score": 0.541477,
        "hf_subset": "kor_Hang-swe_Latn",
        "languages": [
          "kor-Hang",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.432367,
        "recall": 0.531297,
        "f1": 0.457515,
        "accuracy": 0.531297,
        "main_score": 0.457515,
        "hf_subset": "kor_Hang-tam_Taml",
        "languages": [
          "kor-Hang",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.517305,
        "recall": 0.608413,
        "f1": 0.540686,
        "accuracy": 0.608413,
        "main_score": 0.540686,
        "hf_subset": "kor_Hang-tur_Latn",
        "languages": [
          "kor-Hang",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.521336,
        "recall": 0.615423,
        "f1": 0.545321,
        "accuracy": 0.615423,
        "main_score": 0.545321,
        "hf_subset": "kor_Hang-vie_Latn",
        "languages": [
          "kor-Hang",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.48284,
        "recall": 0.569354,
        "f1": 0.504651,
        "accuracy": 0.569354,
        "main_score": 0.504651,
        "hf_subset": "kor_Hang-yue_Hant",
        "languages": [
          "kor-Hang",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.567074,
        "recall": 0.656485,
        "f1": 0.591259,
        "accuracy": 0.656485,
        "main_score": 0.591259,
        "hf_subset": "kor_Hang-zho_Hans",
        "languages": [
          "kor-Hang",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.582307,
        "recall": 0.672008,
        "f1": 0.606954,
        "accuracy": 0.672008,
        "main_score": 0.606954,
        "hf_subset": "kor_Hang-zho_Hant",
        "languages": [
          "kor-Hang",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.025281,
        "recall": 0.056084,
        "f1": 0.03019,
        "accuracy": 0.056084,
        "main_score": 0.03019,
        "hf_subset": "kor_Hang-zul_Latn",
        "languages": [
          "kor-Hang",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.522666,
        "recall": 0.611918,
        "f1": 0.545848,
        "accuracy": 0.611918,
        "main_score": 0.545848,
        "hf_subset": "lit_Latn-kor_Hang",
        "languages": [
          "lit-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.621324,
        "recall": 0.702554,
        "f1": 0.643388,
        "accuracy": 0.702554,
        "main_score": 0.643388,
        "hf_subset": "nld_Latn-kor_Hang",
        "languages": [
          "nld-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.526391,
        "recall": 0.618428,
        "f1": 0.550895,
        "accuracy": 0.618428,
        "main_score": 0.550895,
        "hf_subset": "pol_Latn-kor_Hang",
        "languages": [
          "pol-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.599267,
        "recall": 0.683525,
        "f1": 0.622913,
        "accuracy": 0.683525,
        "main_score": 0.622913,
        "hf_subset": "por_Latn-kor_Hang",
        "languages": [
          "por-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.631155,
        "recall": 0.717576,
        "f1": 0.655348,
        "accuracy": 0.717576,
        "main_score": 0.655348,
        "hf_subset": "rus_Cyrl-kor_Hang",
        "languages": [
          "rus-Cyrl",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.623327,
        "recall": 0.705558,
        "f1": 0.646126,
        "accuracy": 0.705558,
        "main_score": 0.646126,
        "hf_subset": "spa_Latn-kor_Hang",
        "languages": [
          "spa-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.443622,
        "recall": 0.529795,
        "f1": 0.464891,
        "accuracy": 0.529795,
        "main_score": 0.464891,
        "hf_subset": "swa_Latn-kor_Hang",
        "languages": [
          "swa-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.63638,
        "recall": 0.718077,
        "f1": 0.65901,
        "accuracy": 0.718077,
        "main_score": 0.65901,
        "hf_subset": "swe_Latn-kor_Hang",
        "languages": [
          "swe-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.488987,
        "recall": 0.585378,
        "f1": 0.514719,
        "accuracy": 0.585378,
        "main_score": 0.514719,
        "hf_subset": "tam_Taml-kor_Hang",
        "languages": [
          "tam-Taml",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.63974,
        "recall": 0.724587,
        "f1": 0.664015,
        "accuracy": 0.724587,
        "main_score": 0.664015,
        "hf_subset": "tur_Latn-kor_Hang",
        "languages": [
          "tur-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.613761,
        "recall": 0.703555,
        "f1": 0.638973,
        "accuracy": 0.703555,
        "main_score": 0.638973,
        "hf_subset": "vie_Latn-kor_Hang",
        "languages": [
          "vie-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.586572,
        "recall": 0.675013,
        "f1": 0.610713,
        "accuracy": 0.675013,
        "main_score": 0.610713,
        "hf_subset": "yue_Hant-kor_Hang",
        "languages": [
          "yue-Hant",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.628697,
        "recall": 0.71357,
        "f1": 0.652384,
        "accuracy": 0.71357,
        "main_score": 0.652384,
        "hf_subset": "zho_Hans-kor_Hang",
        "languages": [
          "zho-Hans",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.64794,
        "recall": 0.729094,
        "f1": 0.670622,
        "accuracy": 0.729094,
        "main_score": 0.670622,
        "hf_subset": "zho_Hant-kor_Hang",
        "languages": [
          "zho-Hant",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.022325,
        "recall": 0.03355,
        "f1": 0.023875,
        "accuracy": 0.03355,
        "main_score": 0.023875,
        "hf_subset": "zul_Latn-kor_Hang",
        "languages": [
          "zul-Latn",
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 25.05738353729248,
  "kg_co2_emissions": null
}